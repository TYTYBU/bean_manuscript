{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF binding perturbation (CIS-BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from MOODS import parsers, tools\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from pybedtools import BedTool\n",
    "from scipy.stats import zscore\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import subprocess\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # ignore warning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"data\"\n",
    "variants_file = os.path.join(DATADIR, \"LDL_variants/LDLvar_credset.xlsx\")\n",
    "# read variants XLSX file\n",
    "variants = pd.read_excel(variants_file, na_values=['*', 'NA', 'N/A', 'nan'])\n",
    "variants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the report to keep columns used in this analysis\n",
    "cols = [\"rsid\", \"CHR\", \"HG19 BP\", \"A1\", \"A2\", \"fdr_adj\", \"MotifRaptor analysis\"] \n",
    "variants = variants[cols].dropna(subset=[ \"CHR\", \"HG19 BP\", \"A1\", \"A2\"])  \n",
    "variants.columns = [\"ID\", \"CHR\", \"POS\", \"REF\", \"ALT\", \"SCORE\", \"TEST\"]\n",
    "variants.reset_index(drop=True, inplace=True)\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast CHR and POS columns data to right data type (int)\n",
    "def correct_chrom(chrom: Union[float, str]) -> Union[int, str]:\n",
    "    if isinstance(chrom, float) and (chrom > 0 and chrom < 23):\n",
    "        return int(chrom)\n",
    "    if isinstance(chrom, str) and chrom.upper() in [\"X\", \"Y\"]:\n",
    "        return chrom.upper()\n",
    "    raise ValueError(f\"Unknown chromosome {chrom}\")\n",
    "variants[\"CHR\"] = variants.apply(lambda x: correct_chrom(x[1]), axis=1)\n",
    "\n",
    "def correct_position(pos: float) -> int:\n",
    "    if pos < 0: \n",
    "        raise ValueError(f\"Forbidden position: {pos}\")\n",
    "    return int(pos)\n",
    "\n",
    "variants[\"POS\"] = variants.apply(lambda x: correct_position(x[2]), axis=1)\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove indels from variants report (artifacts)\n",
    "variants = variants[\n",
    "    (variants.apply(lambda x: len(x[3]) == 1, axis=1)) & \n",
    "    (variants.apply(lambda x: len(x[4]) == 1, axis=1))\n",
    "]\n",
    "variants.reset_index(drop=True, inplace=True)\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign IDs to SNPs with NaN on ID column\n",
    "def assign_snpid(snpid: str, chrom: str, pos: int, ref: str, alt: str) -> str:\n",
    "    if str(snpid) == \"nan\":\n",
    "        return f\"{chrom}_{pos}_{ref}_{alt}\"\n",
    "    return snpid\n",
    "\n",
    "variants[\"ID\"] = variants.apply(\n",
    "    lambda x: assign_snpid(x[0], x[1], x[2], x[3], x[4]), axis=1\n",
    ")\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the report to the marked variants\n",
    "variants = variants[variants.TEST == \"V\"]\n",
    "variants.reset_index(drop=True, inplace=True)\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover 61 bp genomic sequences centred around the SNP positon\n",
    "GENOME = os.path.join(DATADIR, \"hg19/hg19.fa\")\n",
    "snpids = variants.ID.tolist()\n",
    "chroms = variants.CHR.tolist()\n",
    "positions = variants.POS.tolist()\n",
    "coordinates = {\n",
    "    snpid: f\"chr{chroms[i]}\\t{positions[i] - 31}\\t{positions[i] + 30}\" \n",
    "    for i, snpid in enumerate(snpids)\n",
    "}\n",
    "bed = BedTool(\"\\n\".join(list(coordinates.values())), from_string=True)  # create BED object\n",
    "bed = bed.sequence(fi=GENOME)  # recover sequences\n",
    "sequences = {\n",
    "    snpids[i]: sequence \n",
    "    for i, sequence in enumerate(\n",
    "        [\n",
    "            line.strip().upper() \n",
    "            for line in open(bed.seqfn).readlines() \n",
    "            if not line.startswith(\">\")\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reference and alternative sequence reports\n",
    "def compute_alt_sequences(\n",
    "    sequences: Dict[str, str], ref_alleles: List[str], alt_alleles: List[str]\n",
    ") -> Dict[str, str]:\n",
    "    sequences_alt = {}\n",
    "    for i, snpid in enumerate(sequences):\n",
    "        assert sequences[snpid][30] == ref_alleles[i]\n",
    "        seqalt = sequences[snpid][:30] + alt_alleles[i] + sequences[snpid][31:]\n",
    "        assert len(seqalt) == len(sequences[snpid])\n",
    "        sequences_alt[snpid] = seqalt\n",
    "    return sequences_alt\n",
    "\n",
    "def write_fasta(sequences: Dict[str, str], outfasta: str) -> None:\n",
    "    with open(outfasta, mode=\"w\") as outfile:\n",
    "        for snpid in sequences:\n",
    "            outfile.write(f\">{snpid}\\n{sequences[snpid]}\\n\")\n",
    "    assert os.path.isfile(outfasta) and os.stat(outfasta).st_size > 0\n",
    "\n",
    "OUTDIR = \"output\"\n",
    "fastafolder = os.path.join(OUTDIR, \"fasta\")\n",
    "if not os.path.exists(fastafolder):\n",
    "    os.mkdir(fastafolder)\n",
    "ref_alleles = variants.REF.tolist()\n",
    "alt_alleles = variants.ALT.tolist()\n",
    "# write FASTA files\n",
    "write_fasta(sequences, os.path.join(fastafolder, \"ref.fa\"))\n",
    "write_fasta(\n",
    "    compute_alt_sequences(sequences, ref_alleles, alt_alleles), \n",
    "    os.path.join(fastafolder, \"alt.fa\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Cis-BP motifs and compute the corresponding PFMs\n",
    "def read_motif_table(motif_table_file: str) -> Dict[str, str]:\n",
    "    with open(motif_table_file, mode=\"r\") as infile:\n",
    "        motif_table = {\n",
    "            fields[3]: fields[6]\n",
    "            for line in infile\n",
    "            for fields in [line.strip().split()]\n",
    "        }\n",
    "    return motif_table\n",
    "\n",
    "def cisbp2pfm(motif: str) -> np.ndarray:\n",
    "    with open(motif, mode=\"r\") as infile:\n",
    "        infile.readline()  # skip header\n",
    "        pfm = [\n",
    "            list(map(float, line.strip().split()[1:])) for line in infile\n",
    "        ]\n",
    "    motiflen = len(pfm)\n",
    "    pfm = np.matrix(pfm).T\n",
    "    return pfm, motiflen\n",
    "\n",
    "CISBPMOTIFS = os.path.join(DATADIR, \"TFs/cisbp\")\n",
    "cisbpmotifs = glob(os.path.join(CISBPMOTIFS, \"pwms_all_motifs/*.txt\"))\n",
    "cisbp_table = read_motif_table(\n",
    "    os.path.join(CISBPMOTIFS, \"TF_Information_all_motifs_plus.txt\")\n",
    ")\n",
    "pfms = {}\n",
    "for motif in cisbpmotifs:\n",
    "    basename = os.path.basename(motif).replace(\"txt\", \"pfm\")\n",
    "    motifname = \"_\".join(\n",
    "        [basename.replace(\".pfm\", \"\"), cisbp_table[basename.replace(\".pfm\", \"\")]]\n",
    "    )\n",
    "    pfm, motiflen = cisbp2pfm(motif)\n",
    "    if pfm.size == 0:\n",
    "        continue\n",
    "    pfmfile = os.path.join(CISBPMOTIFS, \"pfms\", basename)\n",
    "    np.savetxt(pfmfile, pfm, fmt=\"%.6f\", delimiter=\"\\t\")\n",
    "    pfms[os.path.basename(motif).replace(\".txt\", \"\")] = (motifname, pfmfile, motiflen)\n",
    "pfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute PWMs from PFMs\n",
    "P = 0.0001  # pseudocount\n",
    "BG = tools.flat_bg(4)  # uniform background distribution\n",
    "\n",
    "def minmax_vals(pwm: np.ndarray) -> Tuple[float, float]:\n",
    "    return np.sum(pwm.min(axis=0)), np.sum(pwm.max(axis=0))\n",
    "\n",
    "def compute_pwm(pfmfile: str, outfolder: str) -> np.ndarray:\n",
    "    basename = os.path.basename(pfmfile).replace(\"pfm\", \"pwm\")\n",
    "    assert basename.endswith(\".pwm\")\n",
    "    pwm = np.matrix(parsers.pfm_to_log_odds(pfmfile, BG, P))\n",
    "    minval, maxval = minmax_vals(pwm)\n",
    "    pwmfile = os.path.join(outfolder, basename)\n",
    "    np.savetxt(pwmfile, pwm, fmt=\"%.6f\", delimiter=\"\\t\")\n",
    "    return pwmfile, minval, maxval\n",
    "\n",
    "pwms = {\n",
    "    motifname: compute_pwm(pfms[motifname][1], os.path.join(CISBPMOTIFS, \"pwms\")) \n",
    "    for motifname in pfms\n",
    "}\n",
    "pwms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan reference and alternative sequences using MOODS\n",
    "MOODSSCAN = \"moods-dna.py\"\n",
    "def moods_scan(\n",
    "    fastafile: str, pwmfiles: str, outfile: str, pvalue: Optional[float] = 1\n",
    ") -> None:\n",
    "    code = subprocess.call(\n",
    "        f\"{MOODSSCAN} -S {pwmfiles} -s {fastafile} -p {pvalue} -o {outfile} --batch\",\n",
    "        shell=True,\n",
    "        stdout=subprocess.DEVNULL,\n",
    "        stderr=subprocess.STDOUT,\n",
    "    )\n",
    "    assert code == 0\n",
    "\n",
    "scandir = os.path.join(OUTDIR, \"moods_scan_results\")\n",
    "if not os.path.exists(scandir):\n",
    "    os.mkdir(scandir)\n",
    "pwmfiles = os.path.join(CISBPMOTIFS, \"pwms/*.pwm\")\n",
    "for fastafile in glob(os.path.join(fastafolder, \"*.fa\")):\n",
    "    outfile = os.path.join(scandir, os.path.basename(fastafile).replace(\"fa\", \"txt\"))\n",
    "    assert outfile.endswith(\".txt\")\n",
    "    moods_scan(fastafile, pwmfiles, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan reference and alternative sequences using MOODS and recover significant hits\n",
    "P = 0.0001\n",
    "\n",
    "scandir = os.path.join(OUTDIR, \"moods_scan_results_hits\")\n",
    "if not os.path.exists(scandir):\n",
    "    os.mkdir(scandir)\n",
    "pwmfiles = os.path.join(CISBPMOTIFS, \"pwms/*.pwm\")\n",
    "for fastafile in glob(os.path.join(fastafolder, \"*.fa\")):\n",
    "    outfile = os.path.join(scandir, os.path.basename(fastafile).replace(\"fa\", \"txt\"))\n",
    "    assert outfile.endswith(\".txt\")\n",
    "    moods_scan(fastafile, pwmfiles, outfile, pvalue=P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the reports from scanning results\n",
    "SNPPOS = 31  # snps occur at position 31 \n",
    "\n",
    "def recover_motifname(motif: str) -> str:\n",
    "    return motif.replace(\".pwm\", \"\")\n",
    "\n",
    "def filter_motif_position(scanres: pd.DataFrame, pfms: Dict[str, Tuple]) -> pd.DataFrame:\n",
    "    positions = {\n",
    "        motifname: list(range(SNPPOS - pfms[motifname][2], SNPPOS)) \n",
    "        for motifname in pfms\n",
    "    }\n",
    "    return scanres[scanres.apply(lambda x: x[2] in positions[x[1]], axis=1)]\n",
    "\n",
    "def relative_score(score: float, minscore: float, maxscore: float) -> float:\n",
    "    return (score - minscore) / (maxscore - minscore)\n",
    "\n",
    "def construct_report(\n",
    "    report: str, pfms: Dict[str, Tuple], pwms: Dict[str, Tuple]\n",
    ") -> pd.DataFrame:\n",
    "    scanres = pd.read_csv(report, header=None).drop([6], axis=1)\n",
    "    scanres.columns = [\"SNPID\", \"MOTIF\", \"POS\", \"STRAND\", \"SCORE\", \"SEQUENCE\"]\n",
    "    scanres[\"MOTIF\"] = scanres.apply(lambda x: recover_motifname(x[1]), axis=1)\n",
    "    # filter motif hits not overlapping the SNP\n",
    "    scanres = filter_motif_position(scanres, pfms)\n",
    "    # compute relative scores\n",
    "    scanres[\"RELATIVESCORE\"] = scanres.apply(\n",
    "        lambda x: relative_score(x[4], pwms[x[1]][1], pwms[x[1]][2]), axis=1\n",
    "    )\n",
    "    return scanres\n",
    "\n",
    "scandir = os.path.join(OUTDIR, \"moods_scan_results\")\n",
    "scanreport_ref = construct_report(os.path.join(scandir, \"ref.txt\"), pfms, pwms)\n",
    "scanreport_alt = construct_report(os.path.join(scandir, \"alt.txt\"), pfms, pwms)\n",
    "scanreport_ref.head(), scanreport_alt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two reports and compute the disruption score\n",
    "def disruption_score(score_ref: float, score_alt: float) -> float:\n",
    "    return score_alt - score_ref\n",
    "\n",
    "def label_disruption(disruption: float) -> str:\n",
    "    if disruption < 0:\n",
    "        return \"decrease\"\n",
    "    elif disruption > 0:\n",
    "        return \"increase\"\n",
    "    return \"equal\"\n",
    "\n",
    "scanreport = scanreport_ref.merge(\n",
    "    scanreport_alt, on=[\"SNPID\", \"MOTIF\", \"POS\", \"STRAND\"]\n",
    ")\n",
    "scanreport.columns = [\n",
    "    \"SNPID\", \"MOTIF\", \"POS\", \"STRAND\", \"SCORE_REF\", \"SEQUENCE_REF\", \"RELATIVESCORE_REF\", \"SCORE_ALT\", \"SEQUENCE_ALT\", \"RELATIVESCORE_ALT\"\n",
    "]\n",
    "scanreport[\"DISRUPTION\"] = scanreport.apply(\n",
    "    lambda x: disruption_score(x[6], x[9]), axis=1\n",
    ")  # compute disruption score\n",
    "# label the SNP effect on TF binding according to the disruption score\n",
    "scanreport[\"LABEL\"] = scanreport.apply(lambda x: label_disruption(x[-1]), axis=1)\n",
    "scanreport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check wheter motif matches are hits in the reference, alternative or both sequences\n",
    "def recover_hits(hits: str) -> List[str]:\n",
    "    hits = pd.read_csv(hits, header=None).drop([6], axis=1)\n",
    "    hits.columns = [\"SNPID\", \"MOTIF\", \"POS\", \"STRAND\", \"SCORE\", \"SEQUENCE\"]\n",
    "    hits[\"MOTIF\"] = hits.apply(lambda x: recover_motifname(x[1]), axis=1)\n",
    "    # filter motif hits not overlapping the SNP\n",
    "    hits = filter_motif_position(hits, pfms)\n",
    "    return list(hits.apply(lambda x: f\"{x[0]}_{x[1]}_{x[2]}_{x[3]}\", axis=1))\n",
    "\n",
    "def merge_hits(hits_ref: List[str], hits_alt: List[str]) -> Dict[str, str]:\n",
    "    hits = {h: \"R\" for h in set(hits_ref).difference(set(hits_alt))}\n",
    "    for h in set(hits_alt).difference(set(hits_ref)):\n",
    "        hits[h] = \"A\"\n",
    "    for h in set(hits_ref).intersection(set(hits_alt)):\n",
    "        hits[h] = \"B\"\n",
    "    return hits\n",
    "\n",
    "def assign_hit(snpid: str, motif: str, pos: int, strand: str, hits: Dict[str, str]) -> str:\n",
    "    try:\n",
    "        return hits[f\"{snpid}_{motif}_{pos}_{strand}\"]\n",
    "    except KeyError:\n",
    "        return \"N\"\n",
    "\n",
    "hits = merge_hits(\n",
    "    recover_hits(os.path.join(OUTDIR, \"moods_scan_results_hits/ref.txt\")),\n",
    "    recover_hits(os.path.join(OUTDIR, \"moods_scan_results_hits/alt.txt\"))\n",
    ")\n",
    "scanreport[\"HIT\"] = scanreport.apply(\n",
    "    lambda x: assign_hit(x[0], x[1], x[2], x[3], hits), axis=1\n",
    ")\n",
    "assert (\n",
    "    (\n",
    "        scanreport[scanreport.HIT == \"R\"].shape[0] + \n",
    "        scanreport[scanreport.HIT == \"A\"].shape[0] +\n",
    "        scanreport[scanreport.HIT == \"B\"].shape[0]\n",
    "    ) == len(hits)\n",
    ")\n",
    "scanreport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate FPKM data in the report\n",
    "def recover_fpkm(counts_file: str) -> Dict[str, int]:\n",
    "    with open(counts_file, mode=\"r\") as infile:\n",
    "        infile.readline()  # skip header\n",
    "        fpkm = {\n",
    "            fields[0]: float(fields[6]) \n",
    "            for line in infile \n",
    "            for fields in [line.strip().split()]\n",
    "        }\n",
    "    return fpkm\n",
    "\n",
    "def interpolate_fpkm(motifname: str, fpkm: Dict[str, int]) -> pd.DataFrame:\n",
    "    try:\n",
    "        value = fpkm[motifname.split(\"_\")[-1].upper()]\n",
    "        if str(value) == \"nan\":\n",
    "            return 0\n",
    "        return value\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "fpkm = recover_fpkm(os.path.join(DATADIR, \"HepG2_rnaseq/ENCFF103FSL_genesymbols.tsv\"))\n",
    "scanreport[\"FPKM\"] = scanreport.apply(\n",
    "    lambda x: interpolate_fpkm(pfms[x[1]][0], fpkm), axis=1\n",
    ")\n",
    "scanreport[\"FPKM_ZSCORE\"] = zscore(scanreport[\"FPKM\"])\n",
    "scanreport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot SNP impact on TF binding\n",
    "def select_snp_data(report: pd.DataFrame, snpid: str) -> pd.DataFrame:\n",
    "    report = report[report.SNPID == snpid]\n",
    "    # report[\"DISRUPTION_ABS\"] = np.abs(report[\"DISRUPTION\"])\n",
    "    # values_table = report.groupby(\"MOTIF\")[\"DISRUPTION_ABS\"].max().to_dict()\n",
    "    # report = report[\n",
    "    #     report.apply(lambda x: x[\"DISRUPTION_ABS\"] == values_table[x[1]], axis=1)\n",
    "    # ]\n",
    "    # report = report.loc[report.groupby(\"MOTIF\")[\"DISRUPTION_ABS\"].idxmax()]\n",
    "    # report = report.drop([\"DISRUPTION_ABS\"], axis=1)\n",
    "    return report\n",
    "\n",
    "def plot_tf_disruption(\n",
    "    snpreport: pd.DataFrame, \n",
    "    pfms: Dict[str, Tuple],\n",
    "    outfile: str,\n",
    "    binding_threshold: Optional[float] = 0.9, \n",
    ") -> None:\n",
    "    f, ax = plt.subplots(\n",
    "        1, 1, figsize=(10, 8), dpi=300, facecolor=\"w\", edgecolor=\"w\"\n",
    "    )\n",
    "    norm = plt.Normalize(vmin=0, vmax=max(snpreport[\"FPKM\"]))\n",
    "    snpreport = snpreport.sort_values([\"FPKM\"], ascending=True)\n",
    "    markers = {\"R\": \"v\", \"A\": \"^\", \"B\": \"*\", \"N\": \"s\"}\n",
    "    for hl in [\"N\", \"R\", \"A\", \"B\"]:\n",
    "        snpreport_hit = snpreport[snpreport.HIT == hl]\n",
    "        alpha = 0.25 if hl == \"N\" else 1\n",
    "        s = ax.scatter(\n",
    "            snpreport_hit[\"DISRUPTION\"],\n",
    "            snpreport_hit[\"RELATIVESCORE_REF\"],\n",
    "            s=50,  # 50 pixel\n",
    "            c=snpreport_hit[\"FPKM\"],\n",
    "            cmap=plt.get_cmap(\"coolwarm\"),  # reds colormap\n",
    "            marker=markers[hl],  # squares,\n",
    "            alpha=alpha,\n",
    "            norm=norm,\n",
    "        )\n",
    "        if hl in [\"R\", \"A\", \"B\"]:\n",
    "            hits = snpreport_hit[\n",
    "                (snpreport_hit.RELATIVESCORE_REF > binding_threshold) |\n",
    "                (snpreport_hit.RELATIVESCORE_ALT > binding_threshold)\n",
    "            ]\n",
    "            hits.apply(\n",
    "                lambda x: ax.text(x[10] + 0.05, x[6], pfms[x[1]][0].split(\"_\")[-1], fontsize=10),\n",
    "                axis=1\n",
    "            )\n",
    "    ax.set_xlabel(\"Disruption\", size=14)\n",
    "    ax.set_xlim([-1.1, 1.1])\n",
    "    ax.set_ylabel(\"Binding affinity\", size=14)\n",
    "    ax.set_ylim([-0.1, 1.1])\n",
    "    ax.set_title(f\"TFs affected by SNP {snpid}\", size=16)\n",
    "    ax.grid(True)\n",
    "    ax.axhline(.5, ls=\"--\", color=\"gray\")\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.5)\n",
    "    cax.set_title(\"Expression FPKM\", size=14)\n",
    "    f.colorbar(s, cax=cax, orientation=\"vertical\")\n",
    "    plt.savefig(outfile, format=\"PNG\", dpi=300)\n",
    "\n",
    "figuresdir = os.path.join(OUTDIR, \"figures\")\n",
    "if not os.path.exists(figuresdir):\n",
    "    os.mkdir(figuresdir)\n",
    "for snpid in snpids:\n",
    "    snpreport = select_snp_data(scanreport.copy(), snpid)\n",
    "    plot_tf_disruption(\n",
    "        snpreport, pfms, os.path.join(figuresdir, f\"TF_binding_impact_{snpid}.png\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
